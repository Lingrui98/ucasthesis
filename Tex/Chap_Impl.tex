\chapter{分支预测部件实现}\label{chap:impl}
本章我们详细介绍香山处理器核分支预测部件的实现。我们首先介绍我们选用的硬件描述语言以及代码基础；接着详细介绍一些关键问题的处理方案。

\section{语言和代码基础}
我们的工作基于加州伯克利大学开源的BOOM（Berkeley Out of Order Machine）\cite{asanovic2015berkeley}。它的第三代SonicBOOM\cite{zhao2020sonicboom}是目前性能最高的RISC-V开源乱序处理器核。它的主分支预测器是L-TAGE\cite{seznec2011new}，同样实现了三级覆盖预测结构，但它的频率经评估后只能达到800MHz。

我们在借鉴其总体架构的基础上，复用了其中的部分模块，对一些细节点进行优化，并为L-TAGE\cite{seznec2011new}添加了Statiscal Corrector，实现了TAGE-SC-L\cite{seznec2014tage}分支方向预测器。此外，我们还优化了它的时序，极大地提升了频率。

我们选用了Chisel硬件构造语言\cite{bachrach2012chisel}。它由加州伯克利大学在Scala编程语言的基础上进行开发，实现了一种可以结合高级语言的面向对象和函数式特性的，可以设计高度参数化硬件的语言。它提高了硬件设计的抽象水平，极大地提高了开发效率和可维护性。

\section{关键问题的处理方案}
\subsection{分支历史的管理}
现代分支预测器依赖处理器执行过程中记录的全局分支历史信息，在取指单元进行基于硬件的动态预测，因此分支历史的管理是分支预测部件中至关重要的部分，而准确的分支历史则是高预测准确率的保障。在分支预测部件的实现中，在分支历史的管理方面主要遇到了两个问题：
\begin{enumerate}
    \item 分支历史中的一位表示什么含义？\label{his:q1}
    \item 如何处理多级预测过程中产生不同的分支历史的情况？\label{his:q2}
\end{enumerate}

\subsubsection*{问题\ref{his:q1}}
分支历史的普遍含义是，到当前周期为止，执行过的前n条分支指令的跳转方向。这个含义下，一位分支历史表示某一条动态分支指令的跳转方向。在所有指令全并行预测的框架下，一个时钟周期可能同时预测多条分支指令，如果要对每一条分支指令都计算分支历史，那么会产生17种可能的移位结果，分别对应行内存在0\textasciitilde16条分支指令的情况；而对每一种移位结果中的其中一位新历史而言，它的值也有16种可能的来源。以上两者对应到逻辑上分别是一个17-1和16-1多路选择器，且两者是串行逻辑。如果用二叉树实现，它们最终分别会引入5级和4级逻辑门，两者之和是9级逻辑门。而分支历史的推测更新是时序关键路径所在，此路径上的9级逻辑门是不可接受的。我们为了降低实现复杂度，采用了和BOOM相同的做法，将整个取指请求的所有分支历史压缩成一位，每一拍最多更新一位分支历史。这样是否更新分支历史只取决于行内是否存在有效的分支指令，而更新结果取决于行内有效的分支指令中是否有跳转的。有效分支指令的含义是，该指令位于行内取指PC之后的位置，且在它前面没有跳转的转移指令。由于一行最多只有一条跳转的转移指令，所以行内存在有效跳转分支指令的等价条件是：行内第一条跳转的指令是分支指令。如上的机制减少了分支历史的逻辑复杂度。同时，由于一个取指请求内可能存在多条分支指令，在相同长度的分支历史寄存器配置下，等效的分支历史长度变长了。

\subsubsection*{问题\ref{his:q2}}
为了得到准确的分支历史信息，必须在预测的同时用预测结果对历史进行推测更新，同时也必须在误预测时进行历史状态的恢复。在多级预测的语境下，最新的分支历史信息必须在第一级预测开始时得到。但在第一级预测开始时，它的上一个预测的最终结果还没有拿到。在这种情况下，即使最终的预测结果是正确的，但其相邻的下一个预测所用的分支历史可能是不准确的。由于最终预测结果是正确的，所以后端执行单元也不会检测到预测错误，也就不会发出重定向请求。使用了错误分支历史信息的指令会存在于正确路径上，这与\ref{design:restore_update}中的假设相悖，会导致最终预测性能的损失。

针对这个问题，SonicBOOM\cite{zhao2020sonicboom}实现了简单的解决方案。它在每一级预测结束后检查结果是否与之前的预测相符时，也对预测后推测更新的分支历史进行检查，如果存在不一致，则也冲刷该级之前的流水线。这种方案可以保证正确路径上的预测所用的分支历史也都是正确的，但可能会增加许多预测流水线自冲刷，从而增加取指空泡。

我们在实现中采用了另一种方案。将分支历史寄存器维护在最后一级预测结束后，在最后一级预测结果成功进入下一级流水时更新分支历史寄存器。为了在第一级预测之前获取到最新的分支历史，我们在每一拍都对全部的三个预测结果进行检测，同时按照取指顺序的先后，根据当前所见的预测结果，用正常的历史更新逻辑倒推出最新的分支历史。\\
如图所示\\
在预测结束后，将开始预测时所用的分支历史，和预测结束前看到的分支历史寄存器中的历史（它们可能不同）同时存进分支预测信息的队列。在误预测恢复的时候，将分支历史寄存器重置为预测结束时所见该寄存器中的内容，并根据真实预测结果进行更新；而当预测器表项在分支指令提交更新的时候，以预测时所见的分支历史为准进行更新操作。这样，对于分支历史寄存器，正确路径上的分支指令见到的仍然是准确的分支历史。而对于预测时所使用的分支历史，它的值取决于该条指令的前三个取指请求在预测流水线上的分布和预测结果。只要这两者在相同情况下能保持一定的稳定性，那么最终的预测性能将不会有大的损失。

在这种机制下，前端自身不会产生因分支历史不同而导致的取指空泡，可能的代价包括：
\begin{enumerate}
    \item 多存一份用于更新的分支历史所带来的存储开销
    \item 预测历史不完全准确带来的性能损失
\end{enumerate}
只要此方法的存储开销在可接受的范围内，而预测准确率的损失能被减少的取值空泡掩盖，此方法便有可行性。我们的初步评估结果显示，此方法相对另一种还有性能提升。

\subsection{跨取指包的RVI指令的预测}
由于分支预测和取指紧耦合，分支预测部件实际上需要对取指取到的所有有效指令做预测。出于实现复杂度和时序方面的考虑，我们以取指宽度（32字节）对齐的地址向指令缓存发出取指请求，得到的指令码会根据取指的实际起始PC进行舍弃，仅保留实际起始PC之后的部分。由于带压缩扩展的RISC-V指令集存在两种指令长度：2字节和4字节，实际指令的放置是按2字节对齐的。在上述机制下，会出现一条4字节长的指令被32字节对齐的地址分为两段的情况。此种情况下，第一个取指请求不会认为此指令有效，因为当时并未得到完整的指令。而按照正常的逻辑，指令的预测依据的是指令的开端所在的PC。当一条4字节长的转移指令被32字节对齐的地址分成两段，如果不经特殊处理，就会出现如下情况：它的预测信息在前一个32字节的预测中被读出并丢弃。原因是：在没有拿到完整的指令的前提下，即使预测部件认为它是一条转移指令并预测跳转，也不能直接从跳转目标地址开始下一次取指。这是由于此类指令在我们目前取指逻辑和预测逻辑中的位置有所偏差导致的。如前所述，在预测逻辑中，指令位于指令开端所在的PC。而在取指逻辑中，对于这类指令会记录下它的前半段指令码，待下半段指令码所在的32字节被取回后，将其与对应的后半段指令码拼起来，作为该取指请求中取到的第一条指令。因此，一条这样的RVI指令，在取指单元中的实际指令位置，处于它的后半段指令所在PC。

如果要正确地预测上述情况的转移指令，必须通过某种形式将它的预测信息和在实际取指逻辑中所处的位置结合起来。一种最直接的想法是在这种情况下把预测信息像前半条指令的指令码一样寄存起来，等到预测后半条指令时再插入。这种方法增加了一些寄存器开销，也在预测关键路径添加了一部分逻辑。我们采用了另一种方法，使得这类指令的预测信息自然地写入到后半条指令所对应的位置。我们利用了存储预测信息的队列以取指请求为单位的特性，让预测信息的更新也以取指请求为单位发出。这样一来，前述的位置偏差就不存在了。对于跨取指请求的RVI转移指令，它的更新请求随着它被取到的那个取指请求发出，也就是它的后半段指令所在的位置。而对于其余的转移指令，仍旧更新到了指令开端PC所在的位置。


\subsection{预测器更新问题}
理想的分支预测器假设预测后根据执行结果和表项的预测时状态（即当前状态）即刻更新，但在真实的实现中这两者都不能满足。真实处理器实现有着如下的特点：
\begin{enumerate}
    \item 预测后不可能马上得到真实执行结果，且往往为了保证预测内所含信息的准确性，会在分支指令真正提交时才进行更新，以防止错误路径上的分支污染预测器表项，这样预测和更新就会存在时间差；
    \item 假如用SRAM实现预测器存储，如果要在更新时得到当前状态，需要对SRAM再进行一次读操作，而多口SRAM存储效率相比单口SRAM差距很大，反之若与预测读请求竞争读口，对预测流水线效率影响很大，通常会将预测时的状态暂存下来等到更新时使用；
\end{enumerate}

需要指出的是，在如上的条件下，预测时读出的状态可能是没有经过妥善地更新的。这是因为在一条指令预测的时间点，在处理器的流水线中还存在尚未提交更新的分支指令，其中可能恰好存在同一条静态分支。在更新时，我们无法区别误预测的原因究竟是不是由于预测时使用了“旧”的表项信息。在我们的具体实现中，我们参考BOOM的做法，采取了一种妥协性的做法。我们实现了一个写入前缓存逻辑，在写入SRAM的同时也将写入的索引和内容记录下来。当一个新的更新请求来到时，我们根据暂存的预测信息和执行结果决定写入表项的位置。同时查询写入前缓存，如果存在相同索引的缓存，就以其中的内容代替暂存的预测时状态，在它的基础上得到表项更新后的内容；如果不命中，则仍旧以暂存的预测状态为基础进行更新。这样对于频繁执行的分支，它会保持在写入缓存内，也就会一直在最新状态的基础上进行更新。写入前缓存是寄存器全相联实现，它部分模拟了预测前读表项的操作，对预测和更新时间差带来的性能损失有所弥补。
